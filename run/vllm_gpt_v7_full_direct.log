/users/hideto/miniconda/envs/vLLM_env/lib/python3.12/site-packages/joblib/_multiprocessing_helpers.py:44: UserWarning: [Errno 13] Permission denied.  joblib will operate in serial mode
  warnings.warn("%s.  joblib will operate in serial mode" % (e,))
/users/hideto/miniconda/envs/vLLM_env/lib/python3.12/site-packages/torch/cuda/__init__.py:827: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
/users/hideto/miniconda/envs/vLLM_env/lib/python3.12/site-packages/torch/cuda/__init__.py:1034: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 304: OS call failed or operation not supported on this OS (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:119.)
  r = torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count
INFO 02-17 15:52:22 [importing.py:44] Triton is installed but 0 active driver(s) found (expected 1). Disabling Triton to prevent runtime errors.
INFO 02-17 15:52:22 [importing.py:68] Triton not installed or not compatible; certain GPU-related functions will not be available.
/users/hideto/miniconda/envs/vLLM_env/lib/python3.12/site-packages/torch/cuda/__init__.py:827: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
W0217 15:52:26.065000 2452854 site-packages/torch/utils/cpp_extension.py:117] No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'
Traceback (most recent call last):
  File "/users/hideto/miniconda/envs/vLLM_env/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/users/hideto/miniconda/envs/vLLM_env/lib/python3.12/site-packages/vllm/entrypoints/cli/main.py", line 66, in main
    cmd.subparser_init(subparsers).set_defaults(dispatch_function=cmd.cmd)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/hideto/miniconda/envs/vLLM_env/lib/python3.12/site-packages/vllm/entrypoints/cli/serve.py", line 76, in subparser_init
    serve_parser = make_arg_parser(serve_parser)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/hideto/miniconda/envs/vLLM_env/lib/python3.12/site-packages/vllm/entrypoints/openai/cli_args.py", line 296, in make_arg_parser
    parser = AsyncEngineArgs.add_cli_args(parser)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/hideto/miniconda/envs/vLLM_env/lib/python3.12/site-packages/vllm/engine/arg_utils.py", line 2049, in add_cli_args
    parser = EngineArgs.add_cli_args(parser)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/hideto/miniconda/envs/vLLM_env/lib/python3.12/site-packages/vllm/engine/arg_utils.py", line 1148, in add_cli_args
    vllm_kwargs = get_kwargs(VllmConfig)
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/users/hideto/miniconda/envs/vLLM_env/lib/python3.12/site-packages/vllm/engine/arg_utils.py", line 349, in get_kwargs
    return copy.deepcopy(_compute_kwargs(cls))
                         ^^^^^^^^^^^^^^^^^^^^
  File "/users/hideto/miniconda/envs/vLLM_env/lib/python3.12/site-packages/vllm/engine/arg_utils.py", line 261, in _compute_kwargs
    default = default.default_factory()
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/users/hideto/miniconda/envs/vLLM_env/lib/python3.12/site-packages/pydantic/_internal/_dataclasses.py", line 121, in __init__
    s.__pydantic_validator__.validate_python(ArgsKwargs(args, kwargs), self_instance=s)
  File "/users/hideto/miniconda/envs/vLLM_env/lib/python3.12/site-packages/vllm/config/device.py", line 58, in __post_init__
    raise RuntimeError(
RuntimeError: Failed to infer device type, please set the environment variable `VLLM_LOGGING_LEVEL=DEBUG` to turn on verbose logging to help debug the issue.
