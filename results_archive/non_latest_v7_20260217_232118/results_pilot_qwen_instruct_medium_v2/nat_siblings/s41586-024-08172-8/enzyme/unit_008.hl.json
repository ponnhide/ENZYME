{
  "schema_version": "0.4",
  "ir_kind": "hl",
  "metadata": {
    "title": "Label-aware integration with scPoli",
    "source": {
      "type": "paper",
      "id": "s41586-024-08172-8.pdf"
    }
  },
  "resources": {
    "materials": [],
    "containers": [],
    "equipment": [],
    "samples": [],
    "data": []
  },
  "protocol": {
    "steps": [
      {
        "id": "s1",
        "op": "annotate",
        "inputs": [],
        "outputs": [],
        "params": {},
        "annotations": {
          "description": "Integration of the organoid datasets for HNOCA using the scPoli model from the scArches package."
        }
      },
      {
        "id": "s2",
        "op": "annotate",
        "inputs": [],
        "outputs": [],
        "params": {},
        "annotations": {
          "description": "Batch covariate defined as concatenation of dataset identifier ('id'), biological replicates ('bio_sample'), and technical replicates ('tech_sample'). Resulted in 396 individual batches."
        }
      },
      {
        "id": "s3",
        "op": "annotate",
        "inputs": [],
        "outputs": [],
        "params": {},
        "annotations": {
          "description": "Batch covariate represented in the model as a learned vector of size five."
        }
      },
      {
        "id": "s4",
        "op": "annotate",
        "inputs": [],
        "outputs": [],
        "params": {},
        "annotations": {
          "description": "Top three levels of the RSS-based snapseed cell type annotation used as cell type label input for the scPoli prototype loss."
        }
      },
      {
        "id": "s5",
        "op": "annotate",
        "inputs": [],
        "outputs": [],
        "params": {},
        "annotations": {
          "description": "Hidden layer size of the one-layer scPoli encoder and decoder set to 1,024."
        }
      },
      {
        "id": "s6",
        "op": "annotate",
        "inputs": [],
        "outputs": [],
        "params": {},
        "annotations": {
          "description": "Latent embedding dimension set to ten."
        }
      },
      {
        "id": "s7",
        "op": "annotate",
        "inputs": [],
        "outputs": [],
        "params": {},
        "annotations": {
          "description": "'alpha_epoch_anneal' parameter set to 100."
        }
      },
      {
        "id": "s8",
        "op": "annotate",
        "inputs": [],
        "outputs": [],
        "params": {},
        "annotations": {
          "description": "Unlabelled prototype pretraining not used."
        }
      },
      {
        "id": "s9",
        "op": "annotate",
        "inputs": [],
        "outputs": [],
        "params": {},
        "annotations": {
          "description": "Model trained for seven epochs total, five of which were pretraining epochs."
        }
      }
    ],
    "start_step_id": "s1",
    "edges": [
      {
        "from": "s1",
        "to": "s2"
      },
      {
        "from": "s2",
        "to": "s3"
      },
      {
        "from": "s3",
        "to": "s4"
      },
      {
        "from": "s4",
        "to": "s5"
      },
      {
        "from": "s5",
        "to": "s6"
      },
      {
        "from": "s6",
        "to": "s7"
      },
      {
        "from": "s7",
        "to": "s8"
      },
      {
        "from": "s8",
        "to": "s9"
      }
    ],
    "detail_level": 0
  }
}